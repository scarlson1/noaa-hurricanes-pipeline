id: 03_gcp_paths
namespace: hurricanes
description: |
  Import last 3 years of CSV Data from NOAA: https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r01/access/csv/

inputs:
  - id: dataset
    type: SELECT
    displayName: Select NOAA dataset
    values: ['last3years', 'NA', 'WP', 'ACTIVE']
    defaults: 'last3years'

  - id: year
    type: SELECT
    displayName: Select year
    values: [2024, 2025, 2026, 2027, 2028]
    defaults: 2025
    allowCustomValue: true

  - id: basin
    type: SELECT
    displayName: Select Basin
    values: ['NA', 'EP']
    defaults: 'NA'

  - id: target_table
    type: STRING
    displayName: BigQuery Table
    defaults: 'hurricanes'

  - id: delete_temp_bq_table
    type: BOOL
    displayName: Delete intermediate BigQuery Table
    default: true

variables:
  file: 'ibtracs.{{inputs.dataset}}.list.v04r01.csv'
  # gcs_file: "gs://{{kv('GCP_BUCKET_NAME')}}/{{var.file}}"
  gcs_file: "gs://{{kv('GCP_BUCKET_NAME')}}/{{inputs.dataset}}.csv"
  int_table_name: 'hurricanes_{{inputs.dataset}}'
  table: "{{ kv('GCP_DATASET') }}.{{vars.int_table_name}}"
  data: "{{ outputs.download_csv.outputFiles['ibtracs.' ~ inputs.dataset ~ '.list.v04r01.csv']}}"
  # data: "{{outputs.extract.outputFiles['ibtracs.' ~ inputs.dataset ~ '.list.v04r01.csv']}}"
  # data: "{{outputs.extract.outputFiles[inputs.dataset ~ '_paths_' ~ inputs.year ~ '-' ~ inputs.basin ~ '.csv']}}"
  # ibtracs.last3years.list.v04r01.csv

# https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r01/access/csv/ibtracs.last3years.list.v04r01.csv

tasks:
  - id: set_label
    type: io.kestra.plugin.core.execution.Labels
    labels:
      file: '{{render(vars.file)}}'
      dataset: '{{ inputs.dataset }}'

  - id: download_csv
    type: io.kestra.plugin.scripts.shell.Commands
    outputFiles:
      - '*.csv'
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - wget -qO- https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r01/access/csv/ibtracs.{{ inputs.dataset }}.list.v04r01.csv > {{ render(vars.file) }}

  # alternatively use wget or io.kestra.plugin.fs.local.Download if running locally
  # - id: download_csv
  #   type: io.kestra.plugin.core.http.Download
  #   uri: https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r01/access/csv/ibtracs.{{inputs.dataset}}.list.v04r01.csv
  #   # saveAs: "{{render(vars.data)}}"
  # - id: notify_download_complete
  #   type: io.kestra.plugin.core.log.Log
  #   message: "Downloaded file URI: {{ outputs.download_csv.uri }}"
  - id: upload_to_gcs
    type: io.kestra.plugin.gcp.gcs.Upload
    from: '{{ render(vars.data) }}'
    to: '{{ render(vars.gcs_file) }}'
    # from: "{{ outputs.download_csv.uri }}"

  # filter to selected year & selected basin
  - id: bq_table_create
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      CREATE TABLE IF NOT EXISTS `{{ kv('GCP_PROJECT_ID')}}.{{kv('GCP_DATASET')}}.{{ inputs.target_table }}`
      (
        unique_row_id STRING OPTIONS (description = 'A unique identifier for the datapoint, generated by hashing key path datapoint attributes.'),
        name STRING OPTIONS (description = 'Event name'),
        sid STRING NOT NULL OPTIONS (description = 'storm ID'),
        basin STRING OPTIONS (description = 'Basins include: NA - North Atlantic EP - Eastern North Pacific WP - Western North Pacific NI - North Indian SI - South Indian SP - Southern Pacific SA - South Atlantic MM - Missing'),
        season STRING  OPTIONS (description = 'string representation of year'),
        iso_time TIMESTAMP  OPTIONS (description = 'timestamp of datapoint'),
        usa_sshs INTEGER OPTIONS (description = 'Saffir-Simpson Hurricane Scale information based on the wind speed provided by the US agency wind speed (US agencies provide 1-minute wind speeds) -5 = Unknown [XX] -4 = Post-tropical [EX/nET/nPT] -3 = Miscellaneous disturbances [WV/nLO/nDB/nDS/nIN/nMD] -2 = Subtropical [SS/nSD] Tropical systems classified based on wind speeds [TD/nTS/nHU/nTY,/nTC/nST/nHR] -1 = Tropical depression (W<34) 0 = Tropical storm [34<W<64] 1 = Category 1 [64<=W<83] 2 = Category 2 [83<=W<96] 3 = Category 3 [96<=W<113] 4 = Category 4 [113<=W<137] 5 = Category 5 [W >= 137]'),
        nature STRING  OPTIONS (description = 'Combined storm type. This is assigned based on all available storm types. They include: DS - Disturbance TS - Tropical ET - Extratropical SS - Subtropical NR - Not reported MX - Mixture'),
        latitude FLOAT64 OPTIONS (description = 'Latitude for current datapoint'),
        longitude FLOAT64  OPTIONS (description = 'Longitude for current datapoint'),
        usa_status STRING OPTIONS (description = 'Category of event at point in time'),
        timestamp STRING OPTIONS (description = 'Event data point timestamp')
      )

  # cockroachDB calculated columns
  # point_id UUID NOT NULL DEFAULT gen_random_uuid(),
  # rowid INT8 NOT VISIBLE NOT NULL DEFAULT unique_rowid(),
  # year INTEGER NULL AS (season),
  # category INTEGER NULL AS (usa_sshs)

  # create external BigQuery table (external = stored in GCS)
  - id: bq_hurricane_data_ext
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      CREATE OR REPLACE EXTERNAL TABLE `{{kv('GCP_PROJECT_ID')}}.{{render(vars.table)}}_ext`
      (
        sid STRING OPTIONS (description = 'storm ID'),
        season STRING OPTIONS (description = 'string representation of year'),
        number STRING,
        basin STRING OPTIONS (description = 'Basins include: NA - North Atlantic EP - Eastern North Pacific WP - Western North Pacific NI - North Indian SI - South Indian SP - Southern Pacific SA - South Atlantic MM - Missing'),
        subbasin string,
        name STRING OPTIONS (description = 'Event name'),        
        iso_time STRING OPTIONS (description = 'timestamp formatted as a string'),
        nature STRING OPTIONS (description = 'Combined storm type. This is assigned based on all available storm types. They include: DS - Disturbance TS - Tropical ET - Extratropical SS - Subtropical NR - Not reported MX - Mixture'),
        lat FLOAT64 OPTIONS (description = 'Latitude for current datapoint'),
        lon FLOAT64 OPTIONS (description = 'Longitude for current datapoint'),
        WMO_WIND NUMERIC,
        WMO_PRES NUMERIC,
        WMO_AGENCY STRING,
        TRACK_TYPE STRING,
        DIST2LAND NUMERIC,
        LANDFALL NUMERIC,
        IFLAG STRING,
        USA_AGENCY STRING,
        USA_ATCF_ID STRING,
        USA_LAT FLOAT64,
        USA_LON FLOAT64,
        USA_RECORD STRING,
        usa_status STRING OPTIONS (description = 'Category of event at point in time'),
        USA_WIND NUMERIC,
        USA_PRES NUMERIC,	
        usa_sshs INTEGER OPTIONS (description = 'Saffir-Simpson Hurricane Scale information based on the wind speed provided by the US agency wind speed (US agencies provide 1-minute wind speeds) -5 = Unknown [XX] -4 = Post-tropical [EX/nET/nPT] -3 = Miscellaneous disturbances [WV/nLO/nDB/nDS/nIN/nMD] -2 = Subtropical [SS/nSD] Tropical systems classified based on wind speeds [TD/nTS/nHU/nTY,/nTC/nST/nHR] -1 = Tropical depression (W<34) 0 = Tropical storm [34<W<64] 1 = Category 1 [64<=W<83] 2 = Category 2 [83<=W<96] 3 = Category 3 [96<=W<113] 4 = Category 4 [113<=W<137] 5 = Category 5 [W >= 137]')
      )
      OPTIONS (
        format = 'CSV',
        uris = ['{{render(vars.gcs_file)}}'],
        skip_leading_rows = 2,
        ignore_unknown_values = TRUE
      );

  # TODO: filter down to storms that have min category of at least 1
  # copy data from csv to external bigquery table
  - id: bq_table_tmp
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      CREATE OR REPLACE TABLE `{{ kv('GCP_PROJECT_ID') }}.{{ render(vars.table) }}`
      AS
      SELECT
        TO_HEX(MD5(CONCAT(
          sid, 
          FORMAT_TIMESTAMP('%Y-%m-%d %H:%M:%S', TIMESTAMP(iso_time))
        ))) AS unique_row_id,
        FORMAT_TIMESTAMP('%Y-%m-%dT%H:%M:%SZ', TIMESTAMP(iso_time)) AS timestamp,
        name,
        sid,
        basin,
        season,
        TIMESTAMP(iso_time) as iso_time,
        usa_sshs,
        nature,
        lat AS latitude,
        lon AS longitude,
        usa_status,
      FROM `{{ kv('GCP_PROJECT_ID') }}.{{ render(vars.table) }}_ext`
      WHERE 
        season = '{{ inputs.year }}' 
        AND basin LIKE '{{inputs.basin}}'
        AND lat IS NOT NULL
        AND lon IS NOT NULL;
  # ORDER BY iso_time ASC
  # FORMAT_TIMESTAMP("%Y-%m-%dT%H:%M:%E*S%Ez", iso_time, "UTC")

  - id: bq_merge
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      MERGE INTO `{{ kv('GCP_PROJECT_ID') }}.{{ kv('GCP_DATASET') }}.{{ inputs.target_table }}` T
      USING `{{ kv('GCP_PROJECT_ID') }}.{{ render(vars.table) }}` S
      on T.unique_row_id = S.unique_row_id
      WHEN NOT MATCHED THEN
        INSERT (
          unique_row_id,
          name,
          sid,
          basin,
          season,
          iso_time,
          usa_sshs,
          nature,
          latitude,
          longitude,
          usa_status,
          timestamp
        )
        VALUES (
          S.unique_row_id,
          S.name,
          S.sid,
          S.basin,
          S.season,
          S.iso_time,
          S.usa_sshs,
          S.nature,
          S.latitude,
          S.longitude,
          S.usa_status,
          S.timestamp
        );

  - id: if_yellow_taxi
    type: io.kestra.plugin.core.flow.If
    condition: '{{ inputs.delete_temp_bq_table }}'
    then:
      - id: delete_table
        type: io.kestra.plugin.gcp.bigquery.DeleteTable
        dataset: "{{ kv('GCP_DATASET') }}"
        table: '{{ vars.int_table_name }}'

  - id: purge_files
    type: io.kestra.plugin.core.storage.PurgeCurrentExecutionFiles
    description: If you'd like to explore Kestra outputs, disable it.
    disabled: false

finally:
  - id: notify
    type: io.kestra.plugin.notifications.slack.SlackIncomingWebhook
    url: "{{ secret('SLACK_WEBHOOK_URL') }}"
    payload: '{"text": "Flow {{ flow.id }} finished with status {{ flow.state }}!"}'

pluginDefaults:
  - type: io.kestra.plugin.gcp
    values:
      serviceAccount: "{{ secret('GCP_SERVICE_ACCOUNT') }}"
      projectId: "{{kv('GCP_PROJECT_ID')}}"
      location: "{{kv('GCP_LOCATION')}}"
      bucket: "{{kv('GCP_BUCKET_NAME')}}"
